# [CS229 : Machine Learning](http://cs229.stanford.edu/)

<img src="https://github.com/SKKSaikia/CS229_ML/blob/master/img/cs229.jpg">

The "ML" course at Stanford , or to say the most popular Machine Learning course Worldwide is CS229. CS229 is Math Heavy and is ðŸ”¥, unlike a simplified online version at Coursera, "[Machine Learning](https://www.coursera.org/learn/machine-learning)". I [completed](https://www.coursera.org/account/accomplishments/verify/4G25AQXD9LDG) the [online](https://github.com/rmarquis/coursera-machinelearning) [version](https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford) as a Freshaman and here I take the CS229 Stanford version. I have access to the 2013 video lectures of CS229 from [ClassX](http://classx.stanford.edu/) (I downloaded them, while I was a visiting student at Stanford). All in all, we have the slides, notes from the course website to learn the content. Stay truthful, maintain Honor Code and Keep Learning. Learning is a journey! 

No Text , but [Pattern Classification - Richard Duda, Peter Hart and David Stork](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Pattern%20Classification%20by%20Richard%20O.%20Duda%2C%20David%20G.%20Stork%2C%20Peter%20E.Hart%20.pdf) | [handout](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/handout.pdf) | [Syllabus](http://cs229.stanford.edu/syllabus.html) 

ð“„† <b>Important Books : </b><br/>
ð“Š– [Hands on Machine Learning with Scikit Learn and TensorFlow](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Hands%20on%20Machine%20Learning%20with%20Scikit%20Learn%20and%20TensorFlow_2.pdf) <br/>
ð“Š– [Introduction to Machine Learning - Ethem AlpaydÄ±n](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Introduction%20to%20Machine%20Learning%20Ethem%20Alpayd%C4%B1n_machinelearning_2010.pdf) <br/>
ð“Š– [Machine Learning A Probabilistic Perspective](https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf) <br/>
ð“Š– [Optimization for Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Optimization%20for%20Machine%20Learning%20%5BSra%2C%20Nowozin%20%26%20Wright%202011-09-30%5D.pdf) <br/>
ð“Š– [Pattern Recognition and Machine Learning - Bishop](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) <br/>
ð“Š– [Pattern Recognition and Machine Learning Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Pattern%20Recognition%20and%20Machine%20Learning%20Solution.pdf) <br/>

<b> Homework (40%) + Mid-term (20%) + Final Project (40%) </b>

# ðŸ¥¤ Homeworks ([Problem Sets](https://github.com/SKKSaikia/CS229_ML/tree/master/PSET)):

ðŸ›¦ [PSET 0](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps0.pdf) <br/>
ðŸ›¦ [PSET 1](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps1.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps1.txt) - [testdata](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/data.zip)<br/> 
ðŸ›¦ [PSET 2](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps2.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps2.txt) <br/>
ðŸ›¦ [PSET 3](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps3.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps3.txt) - [peppers_numpy](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/peppers_numpy.zip) <br/>
ðŸ›¦ [PSET 4](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps4_v5_release.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps4.txt) - [autograder&solution](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/autograder.zip) <br/>

# Course:

<p align="justify">This course provides a broad introduction to <b>machine learning</b> and <b>statistical pattern recognition</b>. Topics include: <b>supervised learning</b> (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); <b>unsupervised learning</b> (clustering, dimensionality reduction, kernel methods); <b>learning theory</b> (bias/variance tradeoffs; VC theory; large margins); <b>reinforcement learning and adaptive control</b>. The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.</p>

<h2><b> â™ž INTRODUCTION </b></h2>

ð“€½ Basic concepts.

<h2><b> â™ž SUPERVISED LEARNING </b></h2>

ð“€½ Supervised learning setup. LMS. [Supervised Learning, Discriminative Algorithms](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes1.pdf) <br/>
ð“€½ Logistic regression. Perceptron. Exponential family. [Linear Algebra](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/1%20-%20cs229-linalg.pdf) <br/>
ð“€½ Generative learning algorithms. Gaussian discriminant analysis. Naive Bayes. <br/>
ð“€½ [Support Vector Machines](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes2.pdf) <br/>
ð“€½ Model selection and feature selection, [Probability](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/2%20-%20cs229-prob.pdf) <br/>
ð“€½ Evaluating and debugging learning algorithms, [Python](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/CS229_Python_Tutorial.pdf) <br/>

<h2><b> â™ž LEARNING THEORY </b></h2>

ð“€½ [Advice on applying machine learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/ml_application_advice.pdf), [Bias/variance tradeoff](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes4a.pdf) and [error analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes4b.pdf) <br/>
ð“€½ [Regularization and Model Selection](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes5.pdf) <br/>
ð“€½ Practical advice on how to use learning algorithms. <br/>

<h2><b> â™ž DEEP LEARNING </b></h2>

ð“€½ Neural Networks, [Deep Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes-deep_learning.pdf), [Backpropagation](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes-backprop.pdf), [Trees](http://cs229.stanford.edu/notes/rf-notes.pdf) <br/>
ð“€½ [Online Learning and the Perceptron Algorithm](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes6.pdf), Vectorization. <br/>

<h2><b> â™ž UNSUPERVISED LEARNING </b></h2>

ð“€½ Clustering. [Unsupervised Learning, k-means clustering](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes7a.pdf) <br/>
ð“€½ [EM Algorithm](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes8.pdf). [Mixture of Gaussians](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes7b.pdf) <br/>
ð“€½ [Factor analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes9.pdf) <br/>
ð“€½ PCA ([Principal components analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes10.pdf)) <br/>
ð“€½ ICA ([Independent components analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes11.pdf)) <br/>

<h2><b> â™ž REINFORCEMENT LEARNING AND CONTROL </b></h2>

ð“€½ MDPs. Bellman equations, [Reinforcement Learning and Control](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes12.pdf) <br/>
ð“€½ Value iteration and policy iteration. Linear quadratic regulation (LQR), [LQR, DDP and LQG](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes13.pdf) <br/>
ð“€½ Q-learning. Value function approximation. Policy search. Reinforce. POMDPs. <br/>
ð“€½ [On critiques of Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/critiques-ml.pdf) <br/>

<h2><b> Supplementary Notes </b></h2>

â™š Binary classification with +/-1 labels [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/1%20-%20loss-functions.pdf) <br/>
â™š Boosting algorithms and weak learning [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/2%20-%20boosting.pdf) <br/>
â™š Functional after implementing stump_booster.m in PS2. [here](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/3%20-%20boosting_example.m) <br/>
â™š The representer theorem [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/4%20-%20representer-function.pdf) <br/>
â™š Hoeffding's inequality [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/5%20-%20hoeffding.pdf) <br/>

<h2><b> Section Notes </b></h2>

â™š Linear Algebra Review and Reference [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/1%20-%20cs229-linalg.pdf) <br/>
â™š Probability Theory Review [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/2%20-%20cs229-prob.pdf) <br/>
â™š Convex Optimization Overview, Part I [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/4%20-%20cs229-cvxopt.pdf) <br/>
â™š Convex Optimization Overview, Part II [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/5%20-%20cs229-cvxopt2.pdf) <br/>
â™š Hidden Markov Models [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/6%20-%20cs229-hmm.pdf) <br/>
â™š The Multivariate Gaussian Distribution [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/7%20-%20gaussians.pdf) <br/>
â™š More on Gaussian Distribution [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/8%20-%20more_on_gaussians.pdf) <br/>
â™š Gaussian Processes [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/9%20-%20cs229-gaussian_processes.pdf) <br/>

[Exams](https://github.com/SKKSaikia/CS229_ML/tree/master/Exams) - [2018 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/MTfinalTBA_aut_2018.pdf), â›· [2017_Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2017_Aut_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2017_Aut_Midterm_soln.pdf), â›· [2016 Spring](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Spr_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Spr_Midterm_soln.pdf), â›· [2016 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Aut_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Aut_Midterm_2.pdf), â›· [2015 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/midterm2015.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/practicemidterm2sol.pdf), â›· [2014 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/midterm2014.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/practicemidterm1sol.pdf), â›· [MReview](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/cs229-mt-review.pdf)     

âœ¿ [MIT ML](http://machinelearning.mit.edu/) | [ML Cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/) | [CS229 Cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning) | [Google Scholar](https://scholar.google.co.in/) | [arXiv](https://arxiv.org/) | [UCI ML dataset repository](http://archive.ics.uci.edu/ml/index.php)

âœ¿ [Official Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/cs229-notes-all) : [compiled](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/CS229.pdf) | [CS229 Notes by Shervine](https://stanford.edu/~shervine/teaching/cs-229.html) | [Advice on applying ML - Andrew NG](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/ML-advice.pdf) | [Machine learning study guides tailored to CS 229](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning) | [Derivatives Backpropagation and Vectorization](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Derivatives%20Backpropagation%20and%20Vectorization.pdf) | [CS229 More Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES) - [Section Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES/section_notes) - [Supplementary Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES/supplementary_notes) | [cCS229@2008](https://www.youtube.com/watch?v=UzxYlbK2c7E&list=PLA89DCFA6ADACE599) - [syll-text](https://github.com/SKKSaikia/CS229_ML/blob/master/cs229_2008.txt)

âœ¿ <b>[Cheatsheets](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/cheatsheets) : </b><br/>
ð“€¯ [Supervised Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-supervised-learning.pdf)
ð“€¯ [Unsupervised Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-unsupervised-learning.pdf)
ð“€¯ [Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-machine-learning-tips-and-tricks.pdf)
ð“€¯ [Deep Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-deep-learning.pdf)
ð“€¯ [Algebra Calculus](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/refresher-algebra-calculus.pdf)
ð“€¯ [Probability Statistics](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/refresher-probabilities-statistics.pdf)
ð“€¯ [Combined](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/super-cheatsheet-machine-learning.pdf)

# FINAL PROJECT

CS229 gives a lot of importance to Final Project, going through the [past projects](http://cs229.stanford.edu/projects.html) , I was happy to see the dynamic range of wonderful ideas and application of ML all the way (I have the [list](https://github.com/SKKSaikia/CS229_ML/blob/master/CS229%20-%20Poster%20Session%20Number.xlsx) - [e.g](https://youtu.be/Iz_ifpoYE_g), [eg2](https://youtu.be/u5a7fz_NoB4)). Good CS229 projects are either publishable or minor changes to be able to publish the project. [NIPS (NeurIPS)](https://nips.cc/) , [ICML](https://icml.cc/) are the ML conferences to show ML works to other people around the world. I was ecstatic to start my own and did " ".
